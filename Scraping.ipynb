{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SvlBVh5-TAy",
        "outputId": "6ac9d24d-2633-4db2-832c-f717fa7c4d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les données ont été exportées avec succès vers descriptions.xlsx\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrap_description(url):\n",
        "    # Effectuer la requête HTTP\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Vérifier si la requête a réussi (statut 200 OK)\n",
        "    if response.status_code == 200:\n",
        "        # Utiliser BeautifulSoup pour analyser le HTML\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Identifier les balises et classes spécifiques pour les descriptions de logements\n",
        "        descriptions = soup.find_all('ul', class_='ulListing')\n",
        "\n",
        "        # Stocker les descriptions dans une liste\n",
        "        descriptions_list = [description.text.strip() for description in descriptions]\n",
        "\n",
        "        return descriptions_list\n",
        "    else:\n",
        "        print(f'Échec de la requête. Statut : {response.status_code}')\n",
        "        return None\n",
        "\n",
        "# URL de la page de résultats de recherche\n",
        "url = 'https://www.mubawab.ma/fr/ct/casablanca/immobilier-a-louer'\n",
        "\n",
        "# Appel de la fonction pour scraper les descriptions\n",
        "descriptions = scrap_description(url)\n",
        "\n",
        "# Vérifier si des descriptions ont été extraites\n",
        "if descriptions:\n",
        "    # Créer un DataFrame avec les descriptions\n",
        "    df = pd.DataFrame({'Description': descriptions})\n",
        "\n",
        "    # Exporter le DataFrame vers un fichier Excel\n",
        "    df.to_excel('descriptions.xlsx', index=False)\n",
        "\n",
        "    print('Les données ont été exportées avec succès vers descriptions.xlsx')\n",
        "else:\n",
        "    print('Aucune donnée à exporter.')\n"
      ]
    }
  ]
}